{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86b876f1",
   "metadata": {},
   "source": [
    "# Feature Engineering untuk Prediksi Gagal Panen\n",
    "\n",
    "Notebook ini menjelaskan proses feature engineering yang dilakukan pada data panen dan cuaca untuk mempersiapkan data training model GRU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import data_processing as dp\n",
    "import config\n",
    "\n",
    "# Set style untuk visualisasi\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1865bd81",
   "metadata": {},
   "source": [
    "## 1. Memuat Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat data dari CSV\n",
    "df_harvest, df_weather = dp.load_data_from_csv()\n",
    "\n",
    "print(\"Data Panen:\")\n",
    "print(df_harvest.head())\n",
    "print(f\"\\nShape: {df_harvest.shape}\")\n",
    "print(f\"\\nKolom: {df_harvest.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nData Cuaca:\")\n",
    "print(df_weather.head())\n",
    "print(f\"\\nShape: {df_weather.shape}\")\n",
    "print(f\"\\nKolom: {df_weather.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f28669c",
   "metadata": {},
   "source": [
    "## 2. Pembersihan Data Panen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458915ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename kolom untuk kemudahan\n",
    "df_harvest_clean = df_harvest.rename(columns={\n",
    "    config.TARGET_COLUMN: \"Produktivitas\",\n",
    "    config.REGION_COLUMN: \"Wilayah\",\n",
    "    \"Luas Panen Tanaman Padi (ha) (Ha)\": \"LuasPanen\"\n",
    "})\n",
    "\n",
    "# Bersihkan format angka (misal: \"54 987,79\" -> 54987.79)\n",
    "for col in [\"Produktivitas\", \"LuasPanen\"]:\n",
    "    df_harvest_clean[col] = df_harvest_clean[col].apply(dp._clean_numeric_string)\n",
    "\n",
    "# Hapus missing values\n",
    "df_harvest_clean = df_harvest_clean.dropna(subset=[\"Produktivitas\", \"LuasPanen\"])\n",
    "\n",
    "print(\"Data Panen Setelah Pembersihan:\")\n",
    "print(df_harvest_clean.head())\n",
    "print(f\"\\nShape: {df_harvest_clean.shape}\")\n",
    "print(f\"\\nStatistik Deskriptif:\")\n",
    "print(df_harvest_clean[[\"Produktivitas\", \"LuasPanen\", \"Tahun\"]].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e6b84",
   "metadata": {},
   "source": [
    "## 3. Pembuatan Label (Target Variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung Z-score produktivitas per wilayah\n",
    "df_harvest_clean['z_score'] = df_harvest_clean.groupby('Wilayah')['Produktivitas'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std(ddof=0)\n",
    ")\n",
    "\n",
    "# Label 1 (Gagal Panen) jika Z-score di bawah threshold\n",
    "df_harvest_clean['GagalPanen'] = (df_harvest_clean['z_score'] < config.Z_SCORE_THRESHOLD).astype(int)\n",
    "\n",
    "print(\"Distribusi Label:\")\n",
    "print(df_harvest_clean['GagalPanen'].value_counts())\n",
    "print(f\"\\nPersentase Gagal Panen: {df_harvest_clean['GagalPanen'].mean()*100:.2f}%\")\n",
    "\n",
    "# Visualisasi distribusi Z-score\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df_harvest_clean['z_score'], bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=config.Z_SCORE_THRESHOLD, color='r', linestyle='--', label=f'Threshold: {config.Z_SCORE_THRESHOLD}')\n",
    "plt.xlabel('Z-Score Produktivitas')\n",
    "plt.ylabel('Frekuensi')\n",
    "plt.title('Distribusi Z-Score Produktivitas')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df_harvest_clean['GagalPanen'].value_counts().plot(kind='bar', color=['green', 'red'])\n",
    "plt.xlabel('Gagal Panen')\n",
    "plt.ylabel('Jumlah')\n",
    "plt.title('Distribusi Label Gagal Panen')\n",
    "plt.xticks([0, 1], ['Normal', 'Gagal Panen'], rotation=0)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86a724c",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Data Cuaca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7e8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename kolom\n",
    "df_weather_clean = df_weather.rename(columns={config.REGION_COLUMN: \"Wilayah\"})\n",
    "df_weather_clean[config.DATE_COLUMN] = pd.to_datetime(df_weather_clean[config.DATE_COLUMN])\n",
    "\n",
    "print(\"Data Cuaca Setelah Pembersihan:\")\n",
    "print(df_weather_clean.head())\n",
    "print(f\"\\nShape: {df_weather_clean.shape}\")\n",
    "\n",
    "# One-Hot Encoding untuk Cuaca Ekstrem\n",
    "print(\"\\nNilai unik Cuaca Ekstrem:\")\n",
    "print(df_weather_clean[config.WEATHER_EVENT_COLUMN].value_counts().head(10))\n",
    "\n",
    "# One-Hot Encoding\n",
    "df_weather_events = df_weather_clean[config.WEATHER_EVENT_COLUMN].str.get_dummies(sep=', ')\n",
    "df_weather_impacts = df_weather_clean[config.WEATHER_IMPACT_COLUMN].str.get_dummies(sep=' / ')\n",
    "\n",
    "print(f\"\\nJumlah fitur cuaca ekstrem: {df_weather_events.shape[1]}\")\n",
    "print(f\"Jumlah fitur dampak: {df_weather_impacts.shape[1]}\")\n",
    "\n",
    "# Gabungkan\n",
    "df_weather_proc = pd.concat([\n",
    "    df_weather_clean[['Wilayah', config.DATE_COLUMN]], \n",
    "    df_weather_events, \n",
    "    df_weather_impacts\n",
    "], axis=1)\n",
    "\n",
    "print(f\"\\nShape setelah encoding: {df_weather_proc.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b34ae0",
   "metadata": {},
   "source": [
    "## 5. Agregasi Temporal (Harian ke Mingguan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4d6b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregasi harian ke mingguan\n",
    "df_weather_weekly = df_weather_proc.set_index(config.DATE_COLUMN).groupby('Wilayah').resample(config.TIME_AGGREGATION_RULE).sum(numeric_only=True).reset_index()\n",
    "df_weather_weekly['Tahun'] = df_weather_weekly[config.DATE_COLUMN].dt.year\n",
    "\n",
    "print(\"Data Cuaca Setelah Agregasi Mingguan:\")\n",
    "print(df_weather_weekly.head())\n",
    "print(f\"\\nShape: {df_weather_weekly.shape}\")\n",
    "\n",
    "# Visualisasi jumlah kejadian cuaca ekstrem per minggu\n",
    "plt.figure(figsize=(14, 6))\n",
    "sample_region = df_weather_weekly['Wilayah'].iloc[0]\n",
    "sample_data = df_weather_weekly[df_weather_weekly['Wilayah'] == sample_region].set_index(config.DATE_COLUMN)\n",
    "\n",
    "# Ambil beberapa kolom cuaca ekstrem untuk visualisasi\n",
    "weather_cols = [col for col in df_weather_weekly.columns if col not in ['Wilayah', config.DATE_COLUMN, 'Tahun']][:5]\n",
    "sample_data[weather_cols].plot(kind='area', stacked=True, alpha=0.7, figsize=(14, 6))\n",
    "plt.title(f'Kejadian Cuaca Ekstrem per Minggu - {sample_region}')\n",
    "plt.xlabel('Tanggal')\n",
    "plt.ylabel('Jumlah Kejadian')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9163a6",
   "metadata": {},
   "source": [
    "## 6. Penggabungan Data Panen dan Cuaca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603acc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan data cuaca mingguan dengan data panen tahunan\n",
    "df_merged = pd.merge(\n",
    "    df_weather_weekly,\n",
    "    df_harvest_clean,\n",
    "    on=['Wilayah', 'Tahun'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Forward fill dan backward fill untuk data panen\n",
    "cols_to_fill = ['LuasPanen', 'GagalPanen']\n",
    "df_merged[cols_to_fill] = df_merged.groupby('Wilayah')[cols_to_fill].ffill().bfill()\n",
    "df_merged = df_merged.dropna(subset=cols_to_fill)\n",
    "\n",
    "print(\"Data Setelah Penggabungan:\")\n",
    "print(df_merged.head())\n",
    "print(f\"\\nShape: {df_merged.shape}\")\n",
    "print(f\"\\nWilayah yang ada: {df_merged['Wilayah'].nunique()}\")\n",
    "print(f\"Rentang tahun: {df_merged['Tahun'].min()} - {df_merged['Tahun'].max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3edba9",
   "metadata": {},
   "source": [
    "## 7. Normalisasi Fitur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbb1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Hapus kolom non-fitur\n",
    "cols_to_drop = ['Wilayah', config.DATE_COLUMN, 'Tahun', 'Produktivitas', 'Rekap Produksi Padi (ton)', 'z_score']\n",
    "features_df = df_merged.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "print(\"Fitur yang digunakan:\")\n",
    "print(features_df.columns.tolist())\n",
    "print(f\"\\nJumlah fitur: {len(features_df.columns)}\")\n",
    "\n",
    "# Normalisasi dengan MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(features_df)\n",
    "\n",
    "print(f\"\\nShape setelah normalisasi: {scaled_features.shape}\")\n",
    "print(f\"Range nilai: [{scaled_features.min():.3f}, {scaled_features.max():.3f}]\")\n",
    "\n",
    "# Visualisasi distribusi beberapa fitur sebelum dan sesudah normalisasi\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "sample_cols = features_df.columns[:6]\n",
    "\n",
    "for idx, col in enumerate(sample_cols):\n",
    "    row = idx // 3\n",
    "    col_idx = idx % 3\n",
    "    \n",
    "    # Sebelum normalisasi\n",
    "    axes[row, col_idx].hist(features_df[col].values, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[row, col_idx].set_title(f'{col}\\n(Sebelum Normalisasi)')\n",
    "    axes[row, col_idx].set_xlabel('Nilai')\n",
    "    axes[row, col_idx].set_ylabel('Frekuensi')\n",
    "    axes[row, col_idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b90cab",
   "metadata": {},
   "source": [
    "## 8. Persiapan Data untuk Model GRU (Time Series Windowing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d2162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import timeseries_dataset_from_array\n",
    "\n",
    "# Buat dataset time series\n",
    "labels = df_merged['GagalPanen'].values\n",
    "dataset = timeseries_dataset_from_array(\n",
    "    data=scaled_features,\n",
    "    targets=labels,\n",
    "    sequence_length=config.SEQUENCE_LENGTH,\n",
    "    sequence_stride=config.SEQUENCE_STRIDE,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Cek bentuk dataset\n",
    "sample_batch = next(iter(dataset))\n",
    "X_sample, y_sample = sample_batch\n",
    "\n",
    "print(\"Bentuk Dataset:\")\n",
    "print(f\"  Input shape (X): {X_sample.shape}\")\n",
    "print(f\"  Target shape (y): {y_sample.shape}\")\n",
    "print(f\"  Sequence length: {config.SEQUENCE_LENGTH} minggu\")\n",
    "print(f\"  Number of features: {X_sample.shape[2]}\")\n",
    "\n",
    "# Hitung jumlah total samples\n",
    "total_samples = len(list(dataset)) * config.BATCH_SIZE\n",
    "print(f\"\\nTotal samples dalam dataset: {total_samples}\")\n",
    "\n",
    "# Visualisasi beberapa sequence\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "for i in range(4):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    # Ambil satu sequence\n",
    "    seq_idx = i * 5\n",
    "    X_seq = X_sample[seq_idx].numpy()\n",
    "    y_label = y_sample[seq_idx].numpy()\n",
    "    \n",
    "    # Plot beberapa fitur\n",
    "    feature_indices = [0, 1, 2, 3]  # Ambil 4 fitur pertama\n",
    "    for feat_idx in feature_indices:\n",
    "        axes[row, col].plot(X_seq[:, feat_idx], alpha=0.7, label=f'Fitur {feat_idx}')\n",
    "    \n",
    "    axes[row, col].set_title(f'Sequence {seq_idx} - Label: {\"Gagal Panen\" if y_label == 1 else \"Normal\"}')\n",
    "    axes[row, col].set_xlabel('Time Step (Minggu)')\n",
    "    axes[row, col].set_ylabel('Nilai Normalisasi')\n",
    "    axes[row, col].legend()\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ENGINEERING SELESAI!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nData siap untuk training model dengan:\")\n",
    "print(f\"  - Sequence length: {config.SEQUENCE_LENGTH} minggu\")\n",
    "print(f\"  - Number of features: {X_sample.shape[2]}\")\n",
    "print(f\"  - Batch size: {config.BATCH_SIZE}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
