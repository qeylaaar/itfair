{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92e99291",
   "metadata": {},
   "source": [
    "# Model Prototyping - GRU untuk Prediksi Gagal Panen\n",
    "\n",
    "Notebook ini digunakan untuk prototyping dan testing arsitektur model GRU sebelum melakukan hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e815826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import data_processing as dp\n",
    "import model\n",
    "import config\n",
    "\n",
    "# Set seed untuk reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb569b35",
   "metadata": {},
   "source": [
    "## 1. Memuat dan Memproses Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940fb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat data\n",
    "df_harvest, df_weather = dp.load_data_from_csv()\n",
    "\n",
    "# Preprocess\n",
    "dataset, scaler, labels = dp.preprocess_features(\n",
    "    df_harvest, \n",
    "    df_weather, \n",
    "    scaler=None, \n",
    "    is_training=True\n",
    ")\n",
    "\n",
    "# Dapatkan input shape\n",
    "sample_batch = next(iter(dataset))\n",
    "input_shape = (sample_batch[0].shape[1], sample_batch[0].shape[2])\n",
    "\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "print(f\"Sequence length: {config.SEQUENCE_LENGTH}\")\n",
    "print(f\"Number of features: {input_shape[1]}\")\n",
    "\n",
    "# Split data\n",
    "dataset_size = len(list(dataset))\n",
    "val_size = int(dataset_size * config.VALIDATION_SPLIT)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "print(f\"\\nTrain samples: {train_size}\")\n",
    "print(f\"Validation samples: {val_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cce396",
   "metadata": {},
   "source": [
    "## 2. Membangun Model GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model dengan hyperparameter default\n",
    "prototype_model = model.build_model(input_shape, hp=None)\n",
    "\n",
    "# Summary model\n",
    "prototype_model.summary()\n",
    "\n",
    "# Visualisasi arsitektur\n",
    "keras.utils.plot_model(prototype_model, show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbf5f95",
   "metadata": {},
   "source": [
    "## 3. Training Model Prototype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Training\n",
    "print(\"Memulai training...\")\n",
    "history = prototype_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=config.EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359006c",
   "metadata": {},
   "source": [
    "## 4. Visualisasi Training History\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a45f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history.history['loss'], label='Train Loss')\n",
    "axes[0, 0].plot(history.history['val_loss'], label='Val Loss')\n",
    "axes[0, 0].set_title('Model Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "axes[0, 1].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "axes[0, 1].set_title('Model Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].plot(history.history['precision'], label='Train Precision')\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Val Precision')\n",
    "axes[1, 0].set_title('Model Precision')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].plot(history.history['recall'], label='Train Recall')\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Val Recall')\n",
    "axes[1, 1].set_title('Model Recall')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5dd6d",
   "metadata": {},
   "source": [
    "## 5. Evaluasi Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi pada validation set\n",
    "val_predictions = prototype_model.predict(val_dataset, verbose=0)\n",
    "val_labels = np.concatenate([y for x, y in val_dataset], axis=0)\n",
    "\n",
    "# Threshold default\n",
    "threshold = 0.5\n",
    "pred_binary = (val_predictions >= threshold).astype(int)\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report (Threshold = 0.5):\")\n",
    "print(classification_report(val_labels, pred_binary, target_names=['Normal', 'Gagal Panen']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(val_labels, pred_binary)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Normal', 'Gagal Panen'],\n",
    "            yticklabels=['Normal', 'Gagal Panen'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(val_labels, val_predictions)\n",
    "auc_score = roc_auc_score(val_labels, val_predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAUC Score: {auc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871cf614",
   "metadata": {},
   "source": [
    "## 6. Threshold Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd78808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Cari threshold optimal berdasarkan F1-score\n",
    "thresholds = np.arange(0.3, 0.8, 0.05)\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    pred_binary = (val_predictions >= threshold).astype(int)\n",
    "    f1_scores.append(f1_score(val_labels, pred_binary))\n",
    "    precision_scores.append(precision_score(val_labels, pred_binary))\n",
    "    recall_scores.append(recall_score(val_labels, pred_binary))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, f1_scores, label='F1-Score', marker='o')\n",
    "plt.plot(thresholds, precision_scores, label='Precision', marker='s')\n",
    "plt.plot(thresholds, recall_scores, label='Recall', marker='^')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Metric Scores vs Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Threshold optimal\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "print(f\"Threshold optimal: {best_threshold:.3f}\")\n",
    "print(f\"F1-Score: {f1_scores[best_idx]:.3f}\")\n",
    "print(f\"Precision: {precision_scores[best_idx]:.3f}\")\n",
    "print(f\"Recall: {recall_scores[best_idx]:.3f}\")\n",
    "\n",
    "# Evaluasi dengan threshold optimal\n",
    "pred_optimal = (val_predictions >= best_threshold).astype(int)\n",
    "print(\"\\nClassification Report (Threshold Optimal):\")\n",
    "print(classification_report(val_labels, pred_optimal, target_names=['Normal', 'Gagal Panen']))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
